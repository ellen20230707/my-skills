"""
åé¦ˆåˆ†æè¿è¡Œè„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–ç”¨æˆ·æä¾›çš„åé¦ˆCSVæ–‡ä»¶
2. åˆ†ææ¨èå‡†ç¡®æ€§
3. ç”Ÿæˆè°ƒä¼˜å»ºè®®
4. è‡ªåŠ¨åº”ç”¨å‚æ•°è°ƒæ•´

ä½¿ç”¨æ–¹æ³•ï¼š
    python run_feedback_analysis.py

è¦æ±‚ï¼š
- åé¦ˆæ–‡ä»¶éœ€åœ¨ 18:00 å‰æäº¤åˆ° turning_feedback/ ç›®å½•
- æ–‡ä»¶åæ ¼å¼: tuning_feedback_YYYYMMDD.csv
- æ ¼å¼: stock\tBest recommendation buy day

Author: Claude
Date: 2026-02-10
"""

import os
import sys
import glob
import logging
from datetime import datetime
from feedback_analyzer import FeedbackAnalyzer

# é…ç½®æ—¥å¿—
log_dir = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'feedback_analysis.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def find_latest_feedback():
    """æŸ¥æ‰¾æœ€æ–°çš„åé¦ˆæ–‡ä»¶"""
    feedback_dir = os.path.join(os.path.dirname(__file__), 'turning_feedback')
    pattern = os.path.join(feedback_dir, 'tuning_feedback_*.csv')
    files = glob.glob(pattern)

    if not files:
        return None

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    files.sort(key=os.path.getmtime, reverse=True)
    return files[0]


def find_latest_recommendation():
    """æŸ¥æ‰¾æœ€æ–°çš„æ¨èCSVæ–‡ä»¶"""
    rec_dir = os.path.join(os.path.dirname(__file__), 'recommendations')
    pattern = os.path.join(rec_dir, 'recommendation_*.csv')
    files = glob.glob(pattern)

    if not files:
        return None

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    files.sort(key=os.path.getmtime, reverse=True)
    return files[0]


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("ğŸ“Š åé¦ˆåˆ†æå·¥å…·")
    logger.info("=" * 80)
    logger.info(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("")

    # 1. æŸ¥æ‰¾åé¦ˆæ–‡ä»¶
    feedback_file = find_latest_feedback()
    if not feedback_file:
        logger.error("âŒ æœªæ‰¾åˆ°åé¦ˆæ–‡ä»¶")
        logger.info("è¯·ç¡®ä¿åé¦ˆæ–‡ä»¶ä½äº turning_feedback/ ç›®å½•")
        logger.info("æ–‡ä»¶åæ ¼å¼: tuning_feedback_YYYYMMDD.csv")
        return False

    logger.info(f"âœ… æ‰¾åˆ°åé¦ˆæ–‡ä»¶: {os.path.basename(feedback_file)}")

    # 2. æŸ¥æ‰¾æ¨èæ–‡ä»¶
    rec_file = find_latest_recommendation()
    if not rec_file:
        logger.error("âŒ æœªæ‰¾åˆ°æ¨èCSVæ–‡ä»¶")
        logger.info("è¯·ç¡®ä¿å·²ç”Ÿæˆæ¨èæŠ¥å‘Šï¼ˆrecommendation_YYYYMMDD.csvï¼‰")
        return False

    logger.info(f"âœ… æ‰¾åˆ°æ¨èæ–‡ä»¶: {os.path.basename(rec_file)}")
    logger.info("")

    # 3. åˆ›å»ºåˆ†æå™¨
    analyzer = FeedbackAnalyzer(
        feedback_file=feedback_file,
        recommendation_file=rec_file
    )

    # 4. è¯»å–åé¦ˆ
    logger.info("ğŸ“– è¯»å–åé¦ˆæ•°æ®...")
    feedback_data = analyzer.read_feedback()
    logger.info(f"   æ€»åé¦ˆæ•°: {feedback_data['total']}")
    logger.info(f"   æ¨èä¹°å…¥: {feedback_data['should_recommend']}")
    logger.info(f"   ä¸åº”æ¨è: {feedback_data['should_not_recommend']}")
    logger.info("")

    # 5. åˆ†æå‡†ç¡®æ€§
    logger.info("ğŸ¯ åˆ†ææ¨èå‡†ç¡®æ€§...")
    accuracy = analyzer.analyze_accuracy()

    logger.info("=" * 80)
    logger.info("ğŸ“Š å‡†ç¡®æ€§ç»Ÿè®¡")
    logger.info("=" * 80)
    logger.info(f"çœŸé˜³æ€§ (æ­£ç¡®æ¨è):    {accuracy['confusion_matrix']['true_positive']}")
    logger.info(f"å‡é˜³æ€§ (é”™è¯¯æ¨è):    {accuracy['confusion_matrix']['false_positive']}")
    logger.info(f"å‡é˜´æ€§ (é—æ¼æ¨è):    {accuracy['confusion_matrix']['false_negative']}")
    logger.info(f"çœŸé˜´æ€§ (æ­£ç¡®ä¸æ¨è):  {accuracy['confusion_matrix']['true_negative']}")
    logger.info("")
    logger.info(f"ç²¾ç¡®ç‡ (Precision): {accuracy['precision']:.2%}")
    logger.info(f"å¬å›ç‡ (Recall):    {accuracy['recall']:.2%}")
    logger.info(f"F1åˆ†æ•°:             {accuracy['f1_score']:.2%}")
    logger.info("=" * 80)
    logger.info("")

    # 6. åˆ†ææ—¶æœº
    logger.info("â° åˆ†ææ¨èæ—¶æœº...")
    timing = analyzer.analyze_timing()

    logger.info("=" * 80)
    logger.info("ğŸ“… æ¨èæ—¶æœºåˆ†æ")
    logger.info("=" * 80)
    logger.info(f"å¹³å‡æå‰å¤©æ•°: {timing['avg_days_early']:.1f} å¤©")
    logger.info(f"æœ€ä½³å›æº¯å¤©æ•°: {timing['optimal_lookback_days']} å¤©")
    logger.info("")
    logger.info("å¤©æ•°åˆ†å¸ƒ:")
    for days, count in sorted(timing['days_distribution'].items()):
        logger.info(f"  æå‰ {days} å¤©: {count} æ¬¡")
    logger.info("=" * 80)
    logger.info("")

    # 7. ç”Ÿæˆè°ƒä¼˜å»ºè®®
    logger.info("ğŸ”§ ç”Ÿæˆè°ƒä¼˜å»ºè®®...")
    recommendations = analyzer.generate_tuning_recommendations()

    logger.info("=" * 80)
    logger.info("ğŸ’¡ è°ƒä¼˜å»ºè®®")
    logger.info("=" * 80)
    for rec in recommendations:
        logger.info(f"ğŸ“Œ {rec['parameter']}")
        logger.info(f"   å½“å‰å€¼: {rec['current_value']}")
        logger.info(f"   å»ºè®®å€¼: {rec['recommended_value']}")
        logger.info(f"   åŸå› : {rec['reason']}")
        logger.info("")
    logger.info("=" * 80)
    logger.info("")

    # 8. åº”ç”¨è°ƒä¼˜
    logger.info("âœ… åº”ç”¨è°ƒä¼˜å‚æ•°...")
    tuning_path = analyzer.apply_tuning()
    logger.info(f"è°ƒä¼˜é…ç½®å·²ä¿å­˜è‡³: {os.path.basename(tuning_path)}")
    logger.info("")

    # 9. æç¤ºä¸‹æ¬¡è¿è¡Œ
    logger.info("=" * 80)
    logger.info("ğŸ‰ åé¦ˆåˆ†æå®Œæˆï¼")
    logger.info("=" * 80)
    logger.info("ğŸ“ ä¸‹æ¬¡è¿è¡Œæ¨èå·¥å…·æ—¶å°†è‡ªåŠ¨ä½¿ç”¨æ–°çš„å‚æ•°é…ç½®")
    logger.info("ğŸ“Š è°ƒä¼˜é…ç½®æ–‡ä»¶: tuning_config.json")
    logger.info("ğŸ”„ å¦‚éœ€æ¢å¤é»˜è®¤é…ç½®ï¼Œåˆ é™¤ tuning_config.json å³å¯")
    logger.info("=" * 80)

    return True


if __name__ == '__main__':
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)
