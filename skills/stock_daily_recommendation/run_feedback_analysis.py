"""
åé¦ˆåˆ†æè¿è¡Œè„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–ç”¨æˆ·æä¾›çš„åé¦ˆCSVæ–‡ä»¶
2. åˆ†ææ¨èå‡†ç¡®æ€§
3. ç”Ÿæˆè°ƒä¼˜å»ºè®®
4. è‡ªåŠ¨åº”ç”¨å‚æ•°è°ƒæ•´

ä½¿ç”¨æ–¹æ³•ï¼š
    python run_feedback_analysis.py

è¦æ±‚ï¼š
- åé¦ˆæ–‡ä»¶éœ€åœ¨ 18:00 å‰æäº¤åˆ° turning_feedback/ ç›®å½•
- æ–‡ä»¶åæ ¼å¼: tuning_feedback_YYYYMMDD.csv
- æ ¼å¼: stock\tBest recommendation buy day

Author: Claude
Date: 2026-02-10
"""

import os
import sys
import glob
import logging
import json
import numpy as np
from datetime import datetime
from enhanced_feedback_analyzer import EnhancedFeedbackAnalyzer

# é…ç½®æ—¥å¿—
log_dir = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'feedback_analysis.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("ğŸ“Š å¢å¼ºç‰ˆåé¦ˆåˆ†æå·¥å…·")
    logger.info("=" * 80)
    logger.info(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("")

    # 1. åˆ›å»ºå¢å¼ºç‰ˆåˆ†æå™¨
    try:
        analyzer = EnhancedFeedbackAnalyzer(learning_rate=0.15)
    except FileNotFoundError as e:
        logger.error(f"âŒ åˆå§‹åŒ–åˆ†æå™¨å¤±è´¥: {str(e)}")
        logger.info("è¯·ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨")
        return False

    # 2. æŸ¥æ‰¾åé¦ˆæ–‡ä»¶
    feedback_file = analyzer.get_latest_feedback_file()
    if not feedback_file:
        logger.error("âŒ æœªæ‰¾åˆ°åé¦ˆæ–‡ä»¶")
        logger.info("è¯·ç¡®ä¿åé¦ˆæ–‡ä»¶ä½äº turning_feedback/ ç›®å½•")
        logger.info("æ–‡ä»¶åæ ¼å¼: tuning_feedback_YYYYMMDD.csv")
        return False

    logger.info(f"âœ… æ‰¾åˆ°åé¦ˆæ–‡ä»¶: {os.path.basename(feedback_file)}")

    # 3. è¯»å–åé¦ˆ
    logger.info("ğŸ“– è¯»å–åé¦ˆæ•°æ®...")
    feedback_df = analyzer.read_feedback(feedback_file)
    if feedback_df is None:
        logger.error("âŒ è¯»å–åé¦ˆæ–‡ä»¶å¤±è´¥")
        return False

    logger.info(f"   æ€»åé¦ˆæ•°: {len(feedback_df)}")
    should_recommend = feedback_df[feedback_df['Best recommendation buy day'] != 'not recommended']
    should_not_recommend = feedback_df[feedback_df['Best recommendation buy day'] == 'not recommended']
    logger.info(f"   æ¨èä¹°å…¥: {len(should_recommend)}")
    logger.info(f"   ä¸åº”æ¨è: {len(should_not_recommend)}")
    logger.info("")

    # 4. ä»åé¦ˆæ–‡ä»¶åæå–æ—¥æœŸ
    feedback_filename = os.path.basename(feedback_file)
    date_str = feedback_filename.replace('tuning_feedback_', '').replace('.csv', '')
    logger.info(f"åé¦ˆæ—¥æœŸ: {date_str}")

    # 5. åˆ†æå‡†ç¡®æ€§
    logger.info("ğŸ¯ åˆ†ææ¨èå‡†ç¡®æ€§...")
    accuracy = analyzer.analyze_accuracy(feedback_df, date_str)

    if accuracy is None:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°æ¨èCSVæ–‡ä»¶")
        logger.info("è¿™æ˜¯æ­£å¸¸æƒ…å†µ - é¦–æ¬¡è¿è¡Œæˆ–è¿˜æœªç”Ÿæˆæ¨èæŠ¥å‘Š")
        logger.info("åé¦ˆåˆ†æå°†åœ¨ä¸‹æ¬¡ç”Ÿæˆæ¨èæŠ¥å‘Šåè‡ªåŠ¨è¿è¡Œ")
        logger.info("")
        logger.info("æç¤ºï¼šæ¨èå·¥å…·ä¼šåœ¨æ¯å¤©22:00è‡ªåŠ¨ç”ŸæˆCSVæ ¼å¼æŠ¥å‘Š")
        logger.info("=" * 80)
        return True  # æ­£å¸¸é€€å‡ºï¼Œä¸æŠ¥é”™

    logger.info("=" * 80)
    logger.info("ğŸ“Š å‡†ç¡®æ€§ç»Ÿè®¡")
    logger.info("=" * 80)
    logger.info(f"çœŸé˜³æ€§ (æ­£ç¡®æ¨è):    {accuracy['true_positives']}")
    logger.info(f"å‡é˜³æ€§ (é”™è¯¯æ¨è):    {accuracy['false_positives']}")
    logger.info(f"å‡é˜´æ€§ (é—æ¼æ¨è):    {accuracy['false_negatives']}")
    logger.info(f"çœŸé˜´æ€§ (æ­£ç¡®ä¸æ¨è):  {accuracy['true_negatives']}")
    logger.info("")
    logger.info(f"ç²¾ç¡®ç‡ (Precision): {accuracy['precision']:.2%}")
    logger.info(f"å¬å›ç‡ (Recall):    {accuracy['recall']:.2%}")
    logger.info(f"F1åˆ†æ•°:             {accuracy['f1_score']:.2%}")
    logger.info(f"å‡†ç¡®ç‡ (Accuracy):  {accuracy['accuracy']:.2%}")
    logger.info("=" * 80)
    logger.info("")

    # 6. ã€æ–°å¢ã€‘é€æ”¯è‚¡ç¥¨Gapåˆ†æ
    logger.info("ğŸ” è¿›è¡Œé€æ”¯è‚¡ç¥¨Gapåˆ†æ...")
    gap_analysis = analyzer.analyze_stock_gaps(feedback_df, date_str)

    if 'error' in gap_analysis:
        logger.warning(f"âš ï¸  Gapåˆ†æå¤±è´¥: {gap_analysis.get('message', 'æœªçŸ¥é”™è¯¯')}")
        logger.info("å°†ä½¿ç”¨åŸºç¡€è°ƒä¼˜ç­–ç•¥")
        logger.info("")
        gap_analysis = None
    else:
        logger.info("=" * 80)
        logger.info("ğŸ“‹ Gapåˆ†æç»“æœ")
        logger.info("=" * 80)
        logger.info(f"æ­£ç¡®æ¨è (TP): {len(gap_analysis['true_positives'])}")
        logger.info(f"é”™è¯¯æ¨è (FP): {len(gap_analysis['false_positives'])}")
        logger.info(f"é—æ¼æ¨è (FN): {len(gap_analysis['false_negatives'])}")
        logger.info("")

        # å±•ç¤ºå…¸å‹é”™è¯¯æ¡ˆä¾‹ï¼ˆå‰3ä¸ªï¼‰
        if gap_analysis['false_positives']:
            logger.info("âŒ å…¸å‹é”™è¯¯æ¨èæ¡ˆä¾‹:")
            for i, case in enumerate(gap_analysis['false_positives'][:3], 1):
                logger.info(f"  {i}. {case['stock_code']}")
                logger.info(f"     ç‰¹å¾: MACD={case['features']['macd_score']:.0f}, "
                          f"æˆäº¤é‡={case['features']['volume_ratio']:.2f}, "
                          f"è¡¥å……åˆ†={case['features']['enhanced_score']:.0f}")
                logger.info(f"     è¯Šæ–­: {case['diagnosis']}")
            if len(gap_analysis['false_positives']) > 3:
                logger.info(f"  ... å…±{len(gap_analysis['false_positives'])}ä¸ªé”™è¯¯æ¨è")
            logger.info("")

        if gap_analysis['false_negatives']:
            logger.info("âš ï¸  å…¸å‹é—æ¼æ¨èæ¡ˆä¾‹:")
            for i, case in enumerate(gap_analysis['false_negatives'][:3], 1):
                logger.info(f"  {i}. {case['stock_code']} (æœ€ä½³ä¹°å…¥æ—¥: {case['best_date']})")
                logger.info(f"     ç‰¹å¾: MACD={case['features']['macd_score']:.0f}, "
                          f"æˆäº¤é‡={case['features']['volume_ratio']:.2f}, "
                          f"è¡¥å……åˆ†={case['features']['enhanced_score']:.0f}")
                logger.info(f"     åŸå› : {case['reason']}")
            if len(gap_analysis['false_negatives']) > 3:
                logger.info(f"  ... å…±{len(gap_analysis['false_negatives'])}ä¸ªé—æ¼æ¨è")
            logger.info("")

        if gap_analysis['true_positives']:
            logger.info("âœ… æˆåŠŸæ¨èæ¡ˆä¾‹ç‰¹å¾åˆ†å¸ƒ:")
            tp_features = [case['features'] for case in gap_analysis['true_positives']]
            macd_scores = [f['macd_score'] for f in tp_features]
            volumes = [f['volume_ratio'] for f in tp_features]
            logger.info(f"  MACDè¯„åˆ†: å‡å€¼={np.mean(macd_scores):.1f}, ä¸­ä½æ•°={np.median(macd_scores):.1f}")
            logger.info(f"  æˆäº¤é‡æ¯”ç‡: å‡å€¼={np.mean(volumes):.2f}, ä¸­ä½æ•°={np.median(volumes):.2f}")
            logger.info("")

        logger.info("=" * 80)
        logger.info("")

    # 7. ã€æ–°å¢ã€‘ç‰¹å¾æ¨¡å¼åˆ†æ
    if gap_analysis:
        logger.info("ğŸ“Š åˆ†æç‰¹å¾æ¨¡å¼...")
        pattern_analysis = analyzer.analyze_feature_patterns(gap_analysis)

        logger.info("=" * 80)
        logger.info("ğŸ¯ ç‰¹å¾æ¨¡å¼åˆ†æç»“æœ")
        logger.info("=" * 80)

        # å±•ç¤ºé˜ˆå€¼åˆ†æ
        threshold_analysis = pattern_analysis.get('threshold_analysis', {})
        for param, analysis in threshold_analysis.items():
            logger.info(f"ğŸ“Œ {param}")
            logger.info(f"   å½“å‰é˜ˆå€¼: {analysis['current']}")
            logger.info(f"   å»ºè®®é˜ˆå€¼: {analysis['suggested']}")
            logger.info(f"   åˆ†æç»“æœ: {analysis['reason']}")
            logger.info("")

        logger.info("=" * 80)
        logger.info("")

        # 8. ã€æ–°å¢ã€‘ç”Ÿæˆè‡ªé€‚åº”è°ƒä¼˜å»ºè®®
        logger.info("ğŸ”§ ç”Ÿæˆè‡ªé€‚åº”è°ƒä¼˜å»ºè®®...")
        tuning_recommendations = analyzer.generate_adaptive_tuning(pattern_analysis)

        logger.info("=" * 80)
        logger.info("ğŸ’¡ è‡ªé€‚åº”è°ƒä¼˜å»ºè®®")
        logger.info("=" * 80)
        if tuning_recommendations['adjustments']:
            for adj in tuning_recommendations['adjustments']:
                logger.info(f"ğŸ“Œ {adj['parameter']}")
                logger.info(f"   å½“å‰å€¼: {adj['current']}")
                logger.info(f"   å»ºè®®å€¼: {adj['suggested']}")
                logger.info(f"   å®é™…è°ƒæ•´: {adj['actual_adjustment']} (å­¦ä¹ ç‡: {analyzer.learning_rate})")
                logger.info(f"   è°ƒæ•´å¹…åº¦: {adj['delta']:+.2f}")
                logger.info(f"   åŸå› : {adj['reason']}")
                logger.info(f"   é¢„æœŸå½±å“: {adj['expected_impact']}")
                logger.info(f"   ç½®ä¿¡åº¦: {adj['confidence']:.0%}")
                logger.info("")
        else:
            logger.info("å½“å‰å‚æ•°è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€è°ƒæ•´")
        logger.info("=" * 80)
        logger.info("")

    else:
        # å¦‚æœGapåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€è°ƒä¼˜
        logger.info("â° åˆ†ææ¨èæ—¶æœº...")
        timing = analyzer.analyze_timing(feedback_df)

        logger.info("=" * 80)
        logger.info("ğŸ“… æ¨èæ—¶æœºåˆ†æ")
        logger.info("=" * 80)
        if 'message' in timing:
            logger.info(timing['message'])
        else:
            logger.info(f"æœ‰æ•ˆåé¦ˆæ•°: {timing['total_valid']}")
            logger.info(f"å¹³å‡è·ç¦»å¤©æ•°: {timing['avg_days_ago']:.1f} å¤©")
            logger.info(f"å½“å‰å›æº¯å¤©æ•°: {timing['current_lookback']} å¤©")
            logger.info(f"è¦†ç›–ç‡: {timing['coverage_rate']:.2%}")
            logger.info(f"å»ºè®®å›æº¯å¤©æ•°: {timing['suggested_lookback']} å¤©")
        logger.info("=" * 80)
        logger.info("")

        logger.info("ğŸ”§ ç”ŸæˆåŸºç¡€è°ƒä¼˜å»ºè®®...")
        tuning_recommendations = analyzer.generate_tuning_recommendations(accuracy, timing)

        logger.info("=" * 80)
        logger.info("ğŸ’¡ åŸºç¡€è°ƒä¼˜å»ºè®®")
        logger.info("=" * 80)
        if tuning_recommendations['adjustments']:
            for adj in tuning_recommendations['adjustments']:
                logger.info(f"ğŸ“Œ {adj['parameter']}")
                logger.info(f"   å½“å‰å€¼: {adj['current']}")
                logger.info(f"   å»ºè®®å€¼: {adj['suggested']}")
                logger.info(f"   åŸå› : {adj['reason']}")
                logger.info("")
        else:
            logger.info("å½“å‰å‚æ•°è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€è°ƒæ•´")
        logger.info("=" * 80)
        logger.info("")

    # 9. åº”ç”¨è°ƒä¼˜
    if tuning_recommendations['adjustments']:
        logger.info("âœ… åº”ç”¨è°ƒä¼˜å‚æ•°...")

        # è¯»å–ç°æœ‰è°ƒä¼˜é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        tuning_config = {}
        if os.path.exists(analyzer.tuning_config_path):
            try:
                with open(analyzer.tuning_config_path, 'r', encoding='utf-8') as f:
                    tuning_config = json.load(f)
                logger.debug(f"è¯»å–ç°æœ‰è°ƒä¼˜é…ç½®: {tuning_config}")
            except:
                pass

        # æ›´æ–°è°ƒä¼˜å‚æ•°ï¼ˆåªä¿®æ”¹æœ‰å˜åŒ–çš„ï¼‰
        for adj in tuning_recommendations['adjustments']:
            param_name = adj['parameter']
            # ä½¿ç”¨å®é™…è°ƒæ•´å€¼ï¼ˆå¦‚æœæ˜¯è‡ªé€‚åº”è°ƒä¼˜ï¼‰æˆ–å»ºè®®å€¼ï¼ˆå¦‚æœæ˜¯åŸºç¡€è°ƒä¼˜ï¼‰
            param_value = adj.get('actual_adjustment', adj['suggested'])
            tuning_config[param_name] = param_value

        # ä¿å­˜é…ç½®
        with open(analyzer.tuning_config_path, 'w', encoding='utf-8') as f:
            json.dump(tuning_config, f, indent=2, ensure_ascii=False)

        logger.info(f"è°ƒä¼˜é…ç½®å·²ä¿å­˜è‡³: {os.path.basename(analyzer.tuning_config_path)}")
        logger.info("")
    else:
        logger.info("æ— éœ€ç”Ÿæˆè°ƒä¼˜é…ç½®")
        logger.info("")

    # 10. ã€æ–°å¢ã€‘è¿½è¸ªæ”¹è¿›å†å²
    if gap_analysis:
        logger.info("ğŸ“ˆ è®°å½•æ”¹è¿›å†å²...")
        analyzer.track_improvement(accuracy, tuning_recommendations['adjustments'], gap_analysis, date_str)

        # å±•ç¤ºæ”¹è¿›æ€»ç»“
        improvement_summary = analyzer.get_improvement_summary()
        if improvement_summary:
            logger.info("=" * 80)
            logger.info("ğŸ“Š æ”¹è¿›æ€»ç»“")
            logger.info("=" * 80)
            logger.info(f"æ€»è°ƒä¼˜æ¬¡æ•°: {improvement_summary['total_tunings']}")
            logger.info(f"é¦–æ¬¡åˆ†æ: {improvement_summary['first_date']}")
            logger.info(f"æœ€æ–°åˆ†æ: {improvement_summary['latest_date']}")
            logger.info("")
            logger.info("æ€»ä½“æ”¹è¿›:")
            for metric, change in improvement_summary['overall_improvement'].items():
                logger.info(f"  {metric}: {change}")
            logger.info("")
            logger.info(f"æœ€ä½³F1åˆ†æ•°: {improvement_summary['best_f1_score']:.2%} (æ—¥æœŸ: {improvement_summary['best_f1_date']})")
            logger.info("=" * 80)
            logger.info("")

    # 11. æç¤ºä¸‹æ¬¡è¿è¡Œ
    logger.info("=" * 80)
    logger.info("ğŸ‰ å¢å¼ºç‰ˆåé¦ˆåˆ†æå®Œæˆï¼")
    logger.info("=" * 80)
    logger.info("ğŸ“ ä¸‹æ¬¡è¿è¡Œæ¨èå·¥å…·æ—¶å°†è‡ªåŠ¨ä½¿ç”¨æ–°çš„å‚æ•°é…ç½®")
    logger.info("ğŸ“Š è°ƒä¼˜é…ç½®æ–‡ä»¶: tuning_config.json")
    if gap_analysis:
        logger.info("ğŸ“ˆ æ”¹è¿›å†å²æ–‡ä»¶: tuning_history.json")
    logger.info("ğŸ”„ å¦‚éœ€æ¢å¤é»˜è®¤é…ç½®ï¼Œåˆ é™¤ tuning_config.json å³å¯")
    logger.info("=" * 80)

    return True


if __name__ == '__main__':
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)
